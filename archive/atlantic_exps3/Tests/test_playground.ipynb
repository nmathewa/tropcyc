{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#%%\n",
    "\n",
    "#in_fol = '/Volumes/New Volume/Other_works/tropcyc/atlantic_exps2/preprocessing/'\n",
    "#in_fol = '/home/nmathewa/main/GIT/tropcyc/atlantic_exps2/preprocessing/'\n",
    "in_fol = '/Users/nalex2023/main/tropcyc/atlantic_exps3/Preprocessing/'\n",
    "\n",
    "\n",
    "#cifar_data = tf.keras.datasets.cifar10.load_data()\n",
    "\n",
    "#y_labels = cifar_data[0][1]\n",
    "\n",
    "#x = cifar_data[0][0]\n",
    "\n",
    "\n",
    "\n",
    "x_data = np.load(in_fol+'final_arrv3.npy')\n",
    "\n",
    "y_speeds = pd.read_csv(in_fol+'targetsv3.csv')['USA_WIND'].to_numpy()\n",
    "\n",
    "#plt.plot(y_speeds)\n",
    "\n",
    "#%%\n",
    "\n",
    "support_file = pd.read_csv(in_fol+'support_file3.csv').set_index('id')\n",
    "\n",
    "support_file['seq_no'] = support_file.groupby('id').count()['lead_time']\n",
    "\n",
    "sequences = pd.unique(support_file['seq_no'])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#%%\n",
    "\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(x_data, y_speeds, test_size=0.2, random_state=1)\n",
    "\n",
    "\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "#train_y_new = scaler.fit_transform(y_train)\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "max_vals = []\n",
    "min_vals = []\n",
    "\n",
    "\n",
    "for ii in range(x_train.shape[-1]):\n",
    "    max_vals += [x_train[:,:,:,ii].max()]\n",
    "    min_vals += [x_train[:,:,:,ii].min()]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "norm_x_train = (x_train - min_vals)/(np.array(max_vals) - np.array(min_vals))\n",
    "\n",
    "#norm_y_train = (y_train - y_train.mean())/y_train.std()\n",
    "\n",
    "norm_y_train = (y_train - y_train.min())/(y_train.max() - y_train.min())\n",
    "\n",
    "max_vals = []\n",
    "min_vals = []\n",
    "\n",
    "for jj in range(x_test.shape[-1]):\n",
    "    max_vals += [x_test[:,:,:,jj].max()]\n",
    "    min_vals += [x_test[:,:,:,jj].min()]\n",
    "\n",
    "\n",
    "norm_x_test = (x_test - min_vals)/(np.array(max_vals) - np.array(min_vals))\n",
    "\n",
    "#norm_y_train = (y_train - y_train.mean())/y_train.std()\n",
    "\n",
    "norm_y_test = (y_test - y_test.min())/(y_test.max() - y_test.min())\n",
    "\n",
    "\n",
    "\n",
    "#%% Sequencing\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Activation\n",
    "from tensorflow.keras.layers import Conv2D\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import Dropout\n",
    "from tensorflow.keras.layers import MaxPooling2D\n",
    "from tensorflow.keras.layers import Flatten\n",
    "from tensorflow.keras.regularizers import l1_l2\n",
    "from keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPool2D,LSTM, TimeDistributed, ConvLSTM2D\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.layers import ZeroPadding3D\n",
    "from tensorflow.keras.layers import Reshape\n",
    "\n",
    "\n",
    "\n",
    "max_len = sequences.max()\n",
    "\n",
    "\n",
    "# convert tjhe 3d data in to sequences\n",
    "\n",
    "\n",
    "padded_seq_x = []\n",
    "padded_seq_y = [] \n",
    "\n",
    "for ii in sequences:\n",
    "    frame1 = norm_x_train[:ii,:,:,:]\n",
    "    padded_seq_x += [np.pad(frame1,((0,max_len-ii),(0,0),(0,0),(0,0)))]\n",
    "\n",
    "for ii in sequences:\n",
    "    frame1 = norm_y_train[:ii]\n",
    "    padded_seq_y += [np.pad(frame1,((0,max_len-ii)))]\n",
    "\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Conv2D(32, kernel_size=(3, 3),activation='relu',input_shape=(max_len,40,40,9)))\n",
    "model.add(TimeDistributed(Flatten()))\n",
    "\n",
    "model.add(LSTM(128, return_sequences=True,input_shape=(max_len,32,32,9)))\n",
    "\n",
    "model.add(TimeDistributed(Dense(1, activation='relu')))\n",
    "\n",
    "\n",
    "\n",
    "model.compile(loss='mean_squared_error', optimizer='adam', metrics=['mean_squared_error'])\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.0347 - mean_squared_error: 0.0347\n",
      "Epoch 2/10\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.0346 - mean_squared_error: 0.0346\n",
      "Epoch 3/10\n",
      "2/2 [==============================] - 2s 1s/step - loss: 0.0346 - mean_squared_error: 0.0346\n",
      "Epoch 4/10\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.0346 - mean_squared_error: 0.0346\n",
      "Epoch 5/10\n",
      "2/2 [==============================] - 2s 1s/step - loss: 0.0346 - mean_squared_error: 0.0346\n",
      "Epoch 6/10\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.0346 - mean_squared_error: 0.0346\n",
      "Epoch 7/10\n",
      "2/2 [==============================] - 2s 1s/step - loss: 0.0346 - mean_squared_error: 0.0346\n",
      "Epoch 8/10\n",
      "2/2 [==============================] - 2s 1s/step - loss: 0.0346 - mean_squared_error: 0.0346\n",
      "Epoch 9/10\n",
      "2/2 [==============================] - 2s 1s/step - loss: 0.0346 - mean_squared_error: 0.0346\n",
      "Epoch 10/10\n",
      "2/2 [==============================] - 2s 1s/step - loss: 0.0346 - mean_squared_error: 0.0346\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x30528f4f0>"
      ]
     },
     "execution_count": 248,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(np.array(padded_seq), np.array(padded_seq_y), epochs=10, batch_size=32, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Creating variables on a non-first call to a function decorated with tf.function.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[239], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnorm_x_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnorm_y_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m32\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalidation_split\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.2\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/deep/lib/python3.10/site-packages/keras/src/utils/traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[1;32m     68\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m     69\u001b[0m     \u001b[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m---> 70\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     71\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m     72\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m~/miniconda3/envs/deep/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:881\u001b[0m, in \u001b[0;36mFunction._call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    877\u001b[0m   results \u001b[38;5;241m=\u001b[39m tracing_compilation\u001b[38;5;241m.\u001b[39mcall_function(\n\u001b[1;32m    878\u001b[0m       args, kwds, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_variable_creation_config\n\u001b[1;32m    879\u001b[0m   )\n\u001b[1;32m    880\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_created_variables:\n\u001b[0;32m--> 881\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCreating variables on a non-first call to a function\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    882\u001b[0m                      \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m decorated with tf.function.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    883\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m results\n\u001b[1;32m    885\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    886\u001b[0m   \u001b[38;5;66;03m# This is the first call of __call__, so we have to initialize.\u001b[39;00m\n",
      "\u001b[0;31mValueError\u001b[0m: Creating variables on a non-first call to a function decorated with tf.function."
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12, 71)"
      ]
     },
     "execution_count": 224,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "padded_seq[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4608, 40, 360)"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data3d.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "in user code:\n\n    File \"/Users/nalex2023/miniconda3/envs/deep/lib/python3.10/site-packages/keras/src/engine/training.py\", line 1401, in train_function  *\n        return step_function(self, iterator)\n    File \"/Users/nalex2023/miniconda3/envs/deep/lib/python3.10/site-packages/keras/src/engine/training.py\", line 1384, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/Users/nalex2023/miniconda3/envs/deep/lib/python3.10/site-packages/keras/src/engine/training.py\", line 1373, in run_step  **\n        outputs = model.train_step(data)\n    File \"/Users/nalex2023/miniconda3/envs/deep/lib/python3.10/site-packages/keras/src/engine/training.py\", line 1150, in train_step\n        y_pred = self(x, training=True)\n    File \"/Users/nalex2023/miniconda3/envs/deep/lib/python3.10/site-packages/keras/src/utils/traceback_utils.py\", line 70, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n    File \"/Users/nalex2023/miniconda3/envs/deep/lib/python3.10/site-packages/keras/src/engine/input_spec.py\", line 253, in assert_input_compatibility\n        raise ValueError(\n\n    ValueError: Exception encountered when calling layer 'sequential_116' (type Sequential).\n    \n    Input 0 of layer \"conv2d_80\" is incompatible with the layer: expected min_ndim=4, found ndim=2. Full shape received: (1, 71)\n    \n    Call arguments received by layer 'sequential_116' (type Sequential):\n      • inputs=tf.Tensor(shape=(1, 71), dtype=float32)\n      • training=True\n      • mask=None\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[174], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpadded_seq\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnorm_y_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/deep/lib/python3.10/site-packages/keras/src/utils/traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[1;32m     68\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m     69\u001b[0m     \u001b[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m---> 70\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     71\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m     72\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m/var/folders/bt/kswp83jx5mj4bn1bjkh9g4rsg_b7ks/T/__autograph_generated_file7xquorz0.py:15\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.tf__train_function\u001b[0;34m(iterator)\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     14\u001b[0m     do_return \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m---> 15\u001b[0m     retval_ \u001b[38;5;241m=\u001b[39m ag__\u001b[38;5;241m.\u001b[39mconverted_call(ag__\u001b[38;5;241m.\u001b[39mld(step_function), (ag__\u001b[38;5;241m.\u001b[39mld(\u001b[38;5;28mself\u001b[39m), ag__\u001b[38;5;241m.\u001b[39mld(iterator)), \u001b[38;5;28;01mNone\u001b[39;00m, fscope)\n\u001b[1;32m     16\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m:\n\u001b[1;32m     17\u001b[0m     do_return \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "\u001b[0;31mValueError\u001b[0m: in user code:\n\n    File \"/Users/nalex2023/miniconda3/envs/deep/lib/python3.10/site-packages/keras/src/engine/training.py\", line 1401, in train_function  *\n        return step_function(self, iterator)\n    File \"/Users/nalex2023/miniconda3/envs/deep/lib/python3.10/site-packages/keras/src/engine/training.py\", line 1384, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/Users/nalex2023/miniconda3/envs/deep/lib/python3.10/site-packages/keras/src/engine/training.py\", line 1373, in run_step  **\n        outputs = model.train_step(data)\n    File \"/Users/nalex2023/miniconda3/envs/deep/lib/python3.10/site-packages/keras/src/engine/training.py\", line 1150, in train_step\n        y_pred = self(x, training=True)\n    File \"/Users/nalex2023/miniconda3/envs/deep/lib/python3.10/site-packages/keras/src/utils/traceback_utils.py\", line 70, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n    File \"/Users/nalex2023/miniconda3/envs/deep/lib/python3.10/site-packages/keras/src/engine/input_spec.py\", line 253, in assert_input_compatibility\n        raise ValueError(\n\n    ValueError: Exception encountered when calling layer 'sequential_116' (type Sequential).\n    \n    Input 0 of layer \"conv2d_80\" is incompatible with the layer: expected min_ndim=4, found ndim=2. Full shape received: (1, 71)\n    \n    Call arguments received by layer 'sequential_116' (type Sequential):\n      • inputs=tf.Tensor(shape=(1, 71), dtype=float32)\n      • training=True\n      • mask=None\n"
     ]
    }
   ],
   "source": [
    "model.fit(padded_seq, norm_y_train, epochs=10, batch_size=1, verbose=1,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([12, 30, 13,  9, 20, 10,  7, 14, 28, 32, 17,  5,  4, 15, 26, 27,  3,\n",
       "       18,  2, 33,  1, 31, 49, 43, 19,  8, 35, 24,  6, 71, 51, 56, 54, 40,\n",
       "       25, 36, 21, 11, 23, 29, 37, 39, 42, 41, 48, 38, 46, 44, 60, 47, 16,\n",
       "       45, 53, 22])"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(12, 40, 40, 9)\n",
      "(4, 40, 40, 9)\n",
      "(3, 40, 40, 9)\n",
      "(33, 40, 40, 9)\n",
      "(53, 40, 40, 9)\n",
      "(45, 40, 40, 9)\n",
      "(42, 40, 40, 9)\n",
      "(51, 40, 40, 9)\n",
      "(24, 40, 40, 9)\n",
      "(45, 40, 40, 9)\n",
      "(42, 40, 40, 9)\n",
      "(51, 40, 40, 9)\n",
      "(24, 40, 40, 9)\n",
      "(45, 40, 40, 9)\n",
      "(42, 40, 40, 9)\n",
      "(51, 40, 40, 9)\n",
      "(24, 40, 40, 9)\n",
      "(45, 40, 40, 9)\n",
      "(42, 40, 40, 9)\n",
      "(51, 40, 40, 9)\n",
      "(24, 40, 40, 9)\n",
      "(45, 40, 40, 9)\n",
      "(42, 40, 40, 9)\n",
      "(51, 40, 40, 9)\n",
      "(24, 40, 40, 9)\n",
      "(45, 40, 40, 9)\n",
      "(42, 40, 40, 9)\n",
      "(51, 40, 40, 9)\n",
      "(24, 40, 40, 9)\n",
      "(45, 40, 40, 9)\n",
      "(42, 40, 40, 9)\n",
      "(51, 40, 40, 9)\n",
      "(24, 40, 40, 9)\n",
      "(45, 40, 40, 9)\n",
      "(42, 40, 40, 9)\n",
      "(51, 40, 40, 9)\n",
      "(24, 40, 40, 9)\n",
      "(45, 40, 40, 9)\n",
      "(42, 40, 40, 9)\n",
      "(51, 40, 40, 9)\n",
      "(24, 40, 40, 9)\n",
      "(45, 40, 40, 9)\n",
      "(42, 40, 40, 9)\n",
      "(51, 40, 40, 9)\n",
      "(24, 40, 40, 9)\n",
      "(45, 40, 40, 9)\n",
      "(42, 40, 40, 9)\n",
      "(51, 40, 40, 9)\n",
      "(24, 40, 40, 9)\n",
      "(45, 40, 40, 9)\n",
      "(42, 40, 40, 9)\n",
      "(51, 40, 40, 9)\n",
      "(24, 40, 40, 9)\n",
      "(45, 40, 40, 9)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "def train_generator(sequences):\n",
    "    while True:\n",
    "        index = 0\n",
    "\n",
    "        for ii in range(len(sequences)):\n",
    "            seq_len = sequences[index % len(sequences)]\n",
    "            end_index = index + seq_len\n",
    "            end_index = min(end_index, len(x_train))\n",
    "            x = norm_x_train[index:end_index,:,:,:]\n",
    "            y = norm_y_train[index:end_index]\n",
    "            yield x, y\n",
    "            index += seq_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12, 40, 40, 9)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deep",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
